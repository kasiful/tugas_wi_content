{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c4231e-ade1-42c7-b638-3edceb4992f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b216015d-685f-4715-a0df-09037a327a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Menetapkan tanggal awal dan tanggal akhir\n",
    "start_date = datetime.date(2023, 12, 30)\n",
    "end_date = datetime.date(2023, 12, 31)\n",
    "\n",
    "# Base URL tanpa parameter tanggal\n",
    "base_url = 'https://www.jpnn.com/indeks?id=&d={}&m={}&y={}'\n",
    "\n",
    "# Iterasi mundur dari tanggal awal ke tanggal akhir\n",
    "current_date = end_date\n",
    "\n",
    "formatted_url = []\n",
    "\n",
    "while current_date >= start_date:\n",
    "    # Membuat URL dengan menambahkan tanggal yang diformat\n",
    "    formatted_url.append(base_url.format(current_date.day, current_date.month, current_date.year))\n",
    "    \n",
    "    # Mengurangi satu hari\n",
    "    current_date -= datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46ef0bf1-6da1-41be-95df-750ca58c887b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.jpnn.com/indeks?id=&d=31&m=12&y=2023',\n",
       " 'https://www.jpnn.com/indeks?id=&d=30&m=12&y=2023']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_url[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663a6888-6258-4a43-8a1b-90e14b36decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Membuat koneksi ke database SQLite\n",
    "conn = sqlite3.connect('./news_data.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Membuat tabel baru jika belum ada\n",
    "c.execute('''\n",
    "CREATE TABLE IF NOT EXISTS news (\n",
    "    judul TEXT,\n",
    "    url TEXT,\n",
    "    rubrik TEXT,\n",
    "    tanggal TEXT\n",
    ")\n",
    "''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbf81d1-c251-490d-bd65-aea147538afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8b40a07-c972-4f6b-acff-41c7e119efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb718c91-c490-42a8-97c2-df3ccdec0b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# mengambil informasi per hari\n",
    "for url in tqdm(formatted_url):\n",
    "    \n",
    "    # untuk setiap harinya, kita perlu ambil jumlah pagination\n",
    "\n",
    "    # Mengirim permintaan GET ke URL\n",
    "    response = requests.get(url, verify=False)  # Menonaktifkan verifikasi SSL untuk contoh ini\n",
    "    \n",
    "    # Memastikan permintaan berhasil\n",
    "    if response.status_code == 200:\n",
    "        # Membuat objek lxml HTML dari respons\n",
    "        tree = html.fromstring(response.content)\n",
    "    else:\n",
    "        print(\"Failed to retrieve the page. Status code:\", response.status_code)\n",
    "\n",
    "\n",
    "    # Jika tidak ada elemen <li>, print 1\n",
    "    li_elements = tree.xpath('//*[@id=\"content-utama\"]//div[@class=\"separate-content-list\"]//div[@class=\"pagination\"]/ul/li/a')\n",
    "    \n",
    "    if not li_elements:\n",
    "        n_pagination = 1\n",
    "    else:\n",
    "        # Mencoba menemukan elemen \"Next\"\n",
    "        next_element = tree.xpath('//*[@id=\"content-utama\"]//div[@class=\"separate-content-list\"]//div[@class=\"pagination\"]/ul/li/a[text()=\"Next\"]/..')\n",
    "        \n",
    "        if next_element:\n",
    "            # Mendapatkan elemen sebelum \"Next\"\n",
    "            prev_element = next_element[0].getprevious()\n",
    "            if prev_element is not None:\n",
    "                number = prev_element.xpath('.//text()')[0]\n",
    "                n_pagination = number\n",
    "            else:\n",
    "                # Jika tidak ada elemen sebelum \"Next\", print 1\n",
    "                n_pagination = 1\n",
    "        else:\n",
    "            # Jika tidak ada \"Next\", ambil angka dari elemen <li> terakhir\n",
    "            last_number = li_elements[-1].xpath('.//text()')[0]\n",
    "            n_pagination = last_number\n",
    "\n",
    "\n",
    "    n_pagination = int(n_pagination)\n",
    "\n",
    "    \n",
    "    # sudah dapat pagination, lalu kita scrape tiap elemen per pagination\n",
    "    for page in range(1, n_pagination+1):\n",
    "        \n",
    "        # URL yang ingin di-scrape\n",
    "        url2 = f'{url}&page={page}'\n",
    "    \n",
    "        # Mengirim permintaan GET ke URL\n",
    "        response = requests.get(url2, verify=False)  # Menonaktifkan verifikasi SSL untuk contoh ini\n",
    "        \n",
    "        # Memastikan permintaan berhasil\n",
    "        if response.status_code == 200:\n",
    "            # Membuat objek lxml HTML dari respons\n",
    "            tree = html.fromstring(response.content)\n",
    "        else:\n",
    "            print(\"Failed to retrieve the page. Status code:\", response.status_code)\n",
    "    \n",
    "        \n",
    "        news_list = tree.xpath('//*[@id=\"content-utama\"]//ul[@class=\"content-list\"]/li')\n",
    "        \n",
    "        # Mencetak hasil\n",
    "        for news in news_list:\n",
    "            judul = \"\".join(news.xpath(\".//h1/a/text()\"))\n",
    "            href = news.xpath(\".//h1/a\")[0].get('href')\n",
    "            rubrik = \"\".join(news.xpath(\".//h6/a/strong/text()\"))\n",
    "            tanggal = \"\".join(news.xpath(\".//h6/a/span/text()\"))\n",
    "            \n",
    "            # print(judul)\n",
    "            # print(href)\n",
    "            # print(rubrik)\n",
    "            # print(tanggal)\n",
    "            # print(\"\")\n",
    "\n",
    "            # Menyimpan data ke dalam database\n",
    "            c.execute('''\n",
    "            INSERT INTO news (judul, url, rubrik, tanggal)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "            ''', (judul, href, rubrik, tanggal))\n",
    "            \n",
    "        # Commit perubahan setelah setiap halaman\n",
    "        conn.commit()\n",
    "        # print(\"Data dari halaman\", url2, \"tersimpan\")\n",
    "    \n",
    "        # print(\"=======================\")\n",
    "        # print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41290bbb-1f0b-46c5-baf0-557d012b9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
